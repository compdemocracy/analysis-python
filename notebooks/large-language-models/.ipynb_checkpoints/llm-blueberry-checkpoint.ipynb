{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pol-is/notebooks/blob/master/020-PCA.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#import altair as alt\n",
    "from textwrap import wrap\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.cluster import KMeans\n",
    "import umap\n",
    "\n",
    "import igraph as ig\n",
    "import leidenalg\n",
    "\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'divide': 'warn', 'over': 'warn', 'under': 'ignore', 'invalid': 'warn'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Set up plots\n",
    "plt.figure(figsize=(500, 500))\n",
    "sns.set_context('poster')\n",
    "sns.set_style('white')\n",
    "sns.set(font_scale=.7)\n",
    "sns.set_color_codes()\n",
    "\n",
    "%matplotlib inline\n",
    "np.seterr(divide='ignore', invalid='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import raw data && clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../data/participants-votes.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m../../data/participants-votes.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mparticipant\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m df_comments \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../data/comments.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,index_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcomment-id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/analysis/analysis-venv/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../data/participants-votes.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../data/participants-votes.csv',index_col='participant')\n",
    "df_comments = pd.read_csv('../../data/comments.csv',index_col='comment-id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comments.index = df_comments.index.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata_fields = ['group-id', 'n-comments', 'n-votes', \n",
    "                   'n-agree', 'n-disagree']\n",
    "val_fields = [c for c in df.columns.values if c not in metadata_fields]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# remove statements (columns) which were moderated out\n",
    "statements_all_in = sorted(list(df_comments.loc[df_comments[\"moderated\"] > 0].index.array), key = int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## for a row, count the number of finite values\n",
    "def count_finite(row):\n",
    "    finite = np.isfinite(row[val_fields]) # boolean array of whether each entry is finite\n",
    "    return sum(finite) # count number of True values in `finite`\n",
    "\n",
    "## REMOVE PARTICIPANTS WITH LESS THAN N VOTES check for each row if the number of finite values >= cutoff\n",
    "def select_rows(df, threshold=7):\n",
    "    \n",
    "    number_of_votes = df.apply(count_finite, axis=1)\n",
    "    valid = number_of_votes >= threshold\n",
    "    \n",
    "    return df[valid]\n",
    "    \n",
    "df = select_rows(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metadata = df[metadata_fields]\n",
    "vals = df[val_fields]\n",
    "# If the participant didn't see the statement, it's a null value, here we fill in the nulls with zeros\n",
    "vals = vals.fillna(0)  #<---in paper: column mean\n",
    "vals = vals.sort_values(\"participant\")\n",
    "vals_all_in = vals[statements_all_in]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How sparse is the dataset? How much agree, how much disagree, how much pass? Zero is 'passed' or 'did not see the comment to vote on it'. 1 is agree, -1 is disagree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "melted = vals.melt();\n",
    "all_votes = melted.count();\n",
    "by_type = melted[\"value\"].value_counts();\n",
    "total_possible_votes = all_votes[\"value\"];\n",
    "total_agrees = by_type[1.0];\n",
    "total_disagrees = by_type[-1.0];\n",
    "total_without_vote = by_type[0.0];\n",
    "\n",
    "print(\"Dimensions of matrix:\", df.shape)\n",
    "print(\"Dimensions of matrix:\", vals.shape)\n",
    "print(\"Total number of possible votes:\", total_possible_votes)\n",
    "print(\"Total number of agrees:\", total_agrees)\n",
    "print(\"Total number of disagrees:\", total_disagrees)\n",
    "print(\"Total without vote:\", total_without_vote)\n",
    "print(\"Percent sparse: \", total_without_vote / total_possible_votes,\"%\")\n",
    "\n",
    "## Make sure to check how many people and votes, relative to the total matrix, you are losing given min vote threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full participants * comments matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some things to notice about the matrix: comments are submitted over time, so participants who do not return will only have voted on the statements which were avialable when they arrived. \n",
    "\n",
    "Long horizontal lines: participants who do return show up as a horizontal line sticking out into otherwise blank areas\n",
    "\n",
    "Blank vertical lines: most likely statements which were moderated out of the conversation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,14))\n",
    "sns.heatmap(vals_all_in, center=0, cmap=\"RdYlBu\", ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polis_pca(dataframe, components):\n",
    "    pca_object = PCA(n_components=components) ## pca is apparently different, it wants \n",
    "    pca_object = pca_object.fit(dataframe.T) ## .T transposes the matrix (flips it)\n",
    "    coords = pca_object.components_.T ## isolate the coordinates and flip \n",
    "    explained_variance = pca_object.explained_variance_ratio_\n",
    "\n",
    "    return coords, explained_variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def c(comment, coords):\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    colorMap = {-1:'#A50026', 1:'#313695', 0:'#FEFEC050'}\n",
    "    ax.scatter(\n",
    "        x=coords[:,0],\n",
    "        y=coords[:,1],\n",
    "        c=vals[str(comment)].apply(lambda x: colorMap[x]),\n",
    "        s=10\n",
    "    )\n",
    "    ax.set_title(\"\\n\".join(wrap(str(comment) + \"  \" + str(df_comments['comment-body'][comment]))), fontsize=14)\n",
    "    print('Colorcode is based on how voted not clustering!')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the space explained by how much people vote?\n",
    "\n",
    "In this chart, we take the PCA coordinates and color the participant locations by the number of total votes. Hopefully, it looks random. If it doesn't, we might imagine the following scenario:\n",
    "\n",
    "1. 1000 people vote, and there are very few controversial statements. They do not return.\n",
    "2. 1 person submits a statement which is incredibly controversial. \n",
    "3. 1000 more people vote, the space begins to take on structure, PCA is closely linked to vote count.\n",
    "\n",
    "We know this scenario - that voters don't see controversial comments - happens. Polis mitigates in two ways:\n",
    "* polis eliminates participants who don't vote at least 7 times from the analysis\n",
    "* polis shows several highly controversial comments (large egeinvalue) in the first 10 comments participants see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords, embedding = polis_pca(vals_all_in, 2)\n",
    "\n",
    "plt.figure(figsize=(7, 5), dpi=80)\n",
    "plt.scatter(\n",
    "    x=coords[:,0], \n",
    "    y=coords[:,1], \n",
    "    c=metadata['n-votes'],\n",
    "    cmap=\"magma_r\",\n",
    "    s=5\n",
    ")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Opinion groups\n",
    "\n",
    "To form opinion groups, we take the PCA coordinates and perform K-means clustering with K=100. \n",
    "These fine-graine cluster serve as the basis for a more coarse-grained clustering, also using K-means. \n",
    "<font color='red'>\n",
    "*In fact, we take the 100 centers (obtained from the first K-means clustering), and run additional K-means clustering for K ranging between 2 and 5.*\n",
    "</font>\n",
    "The K for which the silhoutte coefficient (a measure of withing-cluster similarity vs. between-cluster dissimilarity) is optimal is chosen for the opinion groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#given a dataframe, returns the found lables/clusters and the corresponding centers\n",
    "def polis_kmeans_(dataframe, n_clusters=2):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=0).fit(dataframe)\n",
    "    \n",
    "    return kmeans.labels_, kmeans.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_embedding_with_clusters(embedding_,labels_):\n",
    "    print(\"Plotting PCA embeddings with K-means, K=\"+str(np.max(labels_)+1))\n",
    "    fig, ax = plt.subplots(figsize=(7,5))\n",
    "    plt.sca(ax)\n",
    "    ax.scatter(\n",
    "        x=embedding_[:,0],\n",
    "        y=embedding_[:,1],\n",
    "        c=labels_,\n",
    "        cmap=\"tab20\",\n",
    "        s=5\n",
    "    )\n",
    "    #ax.set_title(\"\", fontsize=14)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Step 1 - get PCA clusters \n",
    "embedding, explained_variance = polis_pca(vals_all_in, 2)  \n",
    "print(\"Explained variance:\", explained_variance)\n",
    "\n",
    "# Step 2 - K-means with K=100\n",
    "clusters_100, centers = polis_kmeans_(embedding,n_clusters=100)\n",
    "plot_embedding_with_clusters(embedding, clusters_100)\n",
    "\n",
    "# Step 3 - find optimal K\n",
    "from sklearn.metrics import silhouette_score \n",
    "silhoutte_star = -np.inf\n",
    "for K in range(2,6):\n",
    "    clusters_K, _ = polis_kmeans_(centers,n_clusters=K)\n",
    "    silhouette_K = silhouette_score(centers, clusters_K)\n",
    "    if silhouette_K >= silhoutte_star:\n",
    "        K_star = K\n",
    "        silhoutte_star = silhouette_K\n",
    "        clusters_K_star = clusters_K\n",
    "print('Optimal clusters for K=',str(K_star))\n",
    "plot_embedding_with_clusters(centers,clusters_K_star)\n",
    " \n",
    "# Step 4 - assign each voter to \"optimal\" cluster\n",
    "clusters_star = np.zeros(len(clusters_100))\n",
    "for k in range(100):#\n",
    "    #find all indices with clusters k and assign them new star label\n",
    "    clusters_star[np.where(clusters_100==k)]  = clusters_K_star[k]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Statistics\n",
    "\n",
    "We analyze comments for how strongly they represent each opinion group.\n",
    "For that, the representative metric R_v(g,c) is calculated for all groups g, comments c, and possible votes v.\n",
    "This metric estimates how much more likely participants in group g are vote v on said comment c than those outside group g.\n",
    "\n",
    "*Definition of R_v(g,c):*\n",
    "Let N_v(g,c) be the number of participants in group g who cast vote v on comment c, and let N(g,c)   be the total number of votes for comment c within group g (i.e. <font color='red'> N_{+1}(g,c)+  N_{-1}(g,c) <font> )\n",
    "\n",
    "Defifne P_v(g,c)=(1+N_v(g,v))/(2+N(g,c)) which estimates the probability that a given person in group g votes v on comment c. Then\n",
    "\n",
    "R_v(g,c) = P_v(g,c)/ P_v(g_not,c)\n",
    "\n",
    "where g_not denotes the complement of g, thus all participants not in g."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: Calculate N_v(g,c), N(g,c), and P_v(g,c)\n",
    "N_groups, N_comments = clusters_K_star.max()+1, len(statements_all_in)\n",
    "N_v_g_c = np.zeros([3,N_groups,N_comments]) #create N matrix \n",
    "P_v_g_c = np.zeros([3,N_groups,N_comments])\n",
    "N_g_c = np.zeros([N_groups,N_comments])\n",
    "v_values = [-1,0,1]\n",
    "\n",
    "for g in range(N_groups): \n",
    "    idx_g = np.where(clusters_star == g)[0] #get indices of cluster g; caution_ idx != participant id\n",
    "    for c in range(N_comments):\n",
    "        comment = statements_all_in[c] #comment id\n",
    "        df_c = vals_all_in[str(comment)].iloc[idx_g] #data frame: [participants of group g,comment c], \n",
    "        for v in range(3):\n",
    "            v_value = v_values[v]\n",
    "            N_v_g_c[v,g,c] = (df_c == v_value).sum() #counts all v_value votes in data frame df_c\n",
    "        N_g_c[g,c] = N_v_g_c[0,g,c] + N_v_g_c[2,g,c] #total votes corresponds to votes with +1 or -1  \n",
    "        \n",
    "        for v in range(3):\n",
    "            P_v_g_c[v,g,c] = (1 + N_v_g_c[v,g,c]) / (2 + N_g_c[g,c])\n",
    "        \n",
    "#Step2: calculate R_v(g,c)                           \n",
    "R_v_g_c = np.zeros([3,N_groups,N_comments])\n",
    "for g in range(N_groups): \n",
    "    for c in range(N_comments):\n",
    "        for v in range(3):\n",
    "           R_v_g_c[v,g,c] = P_v_g_c[v,g,c] / np.delete(P_v_g_c[v,:,c],g,0).sum()  # np.delete neglects all entries with group g                                           \n",
    "                                                   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# Comment Selection criterion\n",
    "\n",
    "Given R_v(g,c), how to decide weather comment c is representative for group g?\n",
    "\n",
    "Remember: R_v(g,c)=2 means that comment c is 2 times more likely to be voted v in group g compared to all the other groups. \n",
    "However, this does not tell us how significant this difference is (a very small likelihood multiplied by 2 is still a very small likelihood).\n",
    "\n",
    "<font color='red'> \n",
    "As a measure of significance, we calculate the Fisher exact test. This quantity can be regarded as a measure of correlation between two random variables. In fact, it tests how significantly the obtained sample (in this case votes v of comment c in group g) is different from the 0 hypothesis (in this case, that votes v are drawn from a hypergeometric distribution with parameters given by including all groups on comment c). \n",
    "<font>\n",
    "\n",
    "We weight this significance measure with R_v(g,c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "from scipy.stats import hypergeom\n",
    "\n",
    "v_values = [-1,0,1]\n",
    "p_values = np.zeros([N_groups,N_comments,3])\n",
    "for g in range(N_groups): \n",
    "    idx_g = np.where(clusters_star == g)[0] #get indices of cluster g; caution_ idx != participant id\n",
    "    idx_g_not = np.where(clusters_star != g)[0] #get indices of rest\n",
    "    for c in range(N_comments):\n",
    "        comment = statements_all_in[c] #comment id\n",
    "        \n",
    "        for v in range(3):\n",
    "            v_value = v_values[v]\n",
    "            N_v = (vals_all_in[str(comment)] == v_value).sum()    #totol number of v votes in comment c\n",
    "            N_rest = (vals_all_in[str(comment)]).count() - N_v    #total number of votes =  number of participants\n",
    "            \n",
    "            df_c = vals_all_in[str(comment)].iloc[idx_g]  #get data frame of group g for comment c\n",
    "            N_v_in_g = (df_c == v_value).sum()\n",
    "            N_g = (df_c).count()   \n",
    "            \n",
    "            [M, n, N] = [N_rest+N_v, N_v, N_g]  #hypergeometric distribution parameters https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.hypergeom.html\n",
    "            x = range(N_v_in_g-1 ,N_g+1)\n",
    "            prb = hypergeom.pmf(x, M, n, N).sum() #calculates P(X>=N_v_in_g), i.e. p-value. \n",
    "            p_values[g,c,v] = prb * R_v_g_c[v,g,c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets print the most significant comments for each group!\n",
    "for g in range(N_groups): \n",
    "    idx_ = np.argsort(p_values[g,:,0]) #take only the significant comments\n",
    "    print('----------------------------------')\n",
    "    print('5 significant comments for group ',g)\n",
    "    print('----------------------------------')\n",
    "    for i in range(5):\n",
    "        print(' ')\n",
    "        print(df_comments['comment-body'][idx_[i]])\n",
    "        print(' ')\n",
    "        \n",
    "        #How to embed comments into plot?\n",
    "        #idx_[i]\n",
    "        #participant_comment = np.zeros([1,vals_all_in.shape[0]])\n",
    "        #participant_comment[0,idx_[i]] = 1\n",
    "        #latent_comment = pca_object.transform(participant_comment)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## lets also include the 5 most significant comments into the PCA embeddings\n",
    "## for that, treat a comment as a artificial participant who only voted on the respective comment \n",
    "## and use the already calculated PCA loadings to project to the 2d plane\n",
    "\n",
    "#plot_embedding_with_clusters(centers,clusters_K_star)\n",
    "\n",
    "#pca_object = PCA(n_components=2) ## pca is apparently different, it wants \n",
    "#pca_object = pca_object.fit(vals_all_in.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
